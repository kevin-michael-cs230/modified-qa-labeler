{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertPreTrainedModel, BertModel, BertConfig, BertTokenizer\n",
    "from typing import List, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertForQuestRegression(BertPreTrainedModel):\n",
    "    def __init__(self, config, head_dropout=None):\n",
    "        super(BertForQuestRegression, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.num_labels = config.num_labels\n",
    "        if head_dropout is None:\n",
    "            head_dropout = config.hidden_dropout_prob\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            position_ids=position_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = torch.mean(sequence_output, dim=1)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def load(self, checkpoint, strict=True, **cfg_args):\n",
    "        self.config.__dict__.update(cfg_args)\n",
    "        self.__init__(self.config)\n",
    "\n",
    "        state_dict = torch.load(checkpoint)\n",
    "        return self.load_state_dict(state_dict, strict=strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_TARGETS = [\n",
    "    \"question_asker_intent_understanding\",\n",
    "    \"question_body_critical\",\n",
    "    \"question_conversational\",\n",
    "    \"question_expect_short_answer\",\n",
    "    \"question_fact_seeking\",\n",
    "    \"question_has_commonly_accepted_answer\",\n",
    "    \"question_interestingness_others\",\n",
    "    \"question_interestingness_self\",\n",
    "    \"question_multi_intent\",\n",
    "    \"question_not_really_a_question\",\n",
    "    \"question_opinion_seeking\",\n",
    "    \"question_type_choice\",\n",
    "    \"question_type_compare\",\n",
    "    \"question_type_consequence\",\n",
    "    \"question_type_definition\",\n",
    "    \"question_type_entity\",\n",
    "    \"question_type_instructions\",\n",
    "    \"question_type_procedure\",\n",
    "    \"question_type_reason_explanation\",\n",
    "    \"question_type_spelling\",\n",
    "    \"question_well_written\",\n",
    "]\n",
    "ANSWER_TARGETS = [\n",
    "    \"answer_helpful\",\n",
    "    \"answer_level_of_information\",\n",
    "    \"answer_plausible\",\n",
    "    \"answer_relevance\",\n",
    "    \"answer_satisfaction\",\n",
    "    \"answer_type_instructions\",\n",
    "    \"answer_type_procedure\",\n",
    "    \"answer_type_reason_explanation\",\n",
    "    \"answer_well_written\",\n",
    "]\n",
    "ALL_TARGETS = QUESTION_TARGETS + ANSWER_TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_df,\n",
    "        tokenizer,\n",
    "        max_seg_length=256,\n",
    "        target_cols=\"all_targets\",\n",
    "        answer_ratio=0.5,\n",
    "        title_ratio=0.5,\n",
    "        use_title=True,\n",
    "        use_body=True,\n",
    "        use_answer=True,\n",
    "        title_col=\"question_title\",\n",
    "        body_col=\"question_body\",\n",
    "        answer_col=\"answer\",\n",
    "        title_transform=None,\n",
    "        body_transform=None,\n",
    "        answer_transform=None,\n",
    "    ):\n",
    "        self.tokenizer: PreTrainedTokenizer = tokenizer\n",
    "        self.max_seg_length = max_seg_length\n",
    "        self.target_cols = (\n",
    "            QUESTION_TARGETS + ANSWER_TARGETS\n",
    "            if target_cols is \"all_targets\"\n",
    "            else target_cols\n",
    "        )\n",
    "        self.answer_ratio = answer_ratio\n",
    "        self.title_ratio = title_ratio\n",
    "\n",
    "        if target_cols is not None:\n",
    "            if target_cols is \"all_targets\":\n",
    "                target_cols = ALL_TARGETS\n",
    "            self.targets = data_df[target_cols].values\n",
    "\n",
    "        self.question_title = data_df[title_col].values if use_title else None\n",
    "        self.question_body = data_df[body_col].values if use_body else None\n",
    "        self.answer = data_df[answer_col].values if use_answer else None\n",
    "\n",
    "        self.title_transform = title_transform\n",
    "        self.body_transform = body_transform\n",
    "        self.answer_transform = answer_transform\n",
    "\n",
    "    def _encode_segments(self, *text_segments: List[Text]) -> List[List[int]]:\n",
    "        # if self.transform is not None:\n",
    "        #     text_segments = [self.transform(txt) for txt in text_segments]\n",
    "        return [\n",
    "            self.tokenizer.encode(\n",
    "                txt, max_length=self.max_seg_length, add_special_tokens=False\n",
    "            )\n",
    "            if txt is not None\n",
    "            else []\n",
    "            for txt in text_segments\n",
    "        ]\n",
    "\n",
    "    def _process(self, title=None, body=None, answer=None):\n",
    "        input_ids, attention_mask, token_type_ids = self._prepare_features(\n",
    "            title, body, answer\n",
    "        )\n",
    "\n",
    "        input_ids = self._pad_and_truncate(\n",
    "            input_ids, pad_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        token_type_ids = self._pad_and_truncate(\n",
    "            token_type_ids, pad_value=token_type_ids[-1]\n",
    "        )\n",
    "        attention_mask = self._pad_and_truncate(attention_mask, pad_value=0)\n",
    "        return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "    def _pad_and_truncate(self, features, pad_value=0):\n",
    "        features = list(features[: self.max_seg_length])\n",
    "        features = features + [pad_value,] * (self.max_seg_length - len(features))\n",
    "        features = np.array(features)\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def _balance_segments(\n",
    "        first_segment_length, second_segment_length, second_ratio, max_length\n",
    "    ):\n",
    "        first_segment_length = min(\n",
    "            first_segment_length,\n",
    "            (1 - second_ratio) * max_length\n",
    "            + max(second_ratio * max_length - second_segment_length, 0),\n",
    "        )\n",
    "\n",
    "        second_segment_length = min(\n",
    "            second_segment_length,\n",
    "            second_ratio * max_length\n",
    "            + max((1 - second_ratio) * max_length - first_segment_length, 0),\n",
    "        )\n",
    "\n",
    "        return int(first_segment_length), int(second_segment_length)\n",
    "\n",
    "    def _prepare_features(self, title, body, answer):\n",
    "        title_input_ids, body_input_ids, answer_input_ids = self._encode_segments(\n",
    "            title, body, answer\n",
    "        )\n",
    "\n",
    "        title_length = len(title_input_ids)\n",
    "        body_length = len(body_input_ids)\n",
    "        answer_length = len(answer_input_ids)\n",
    "\n",
    "        question_length, answer_length = self._balance_segments(\n",
    "            title_length + body_length,\n",
    "            answer_length,\n",
    "            self.answer_ratio,\n",
    "            self.max_seg_length,\n",
    "        )\n",
    "\n",
    "        title_length, body_length = self._balance_segments(\n",
    "            title_length, body_length, self.title_ratio, question_length\n",
    "        )\n",
    "\n",
    "        # TODO: generalize this\n",
    "        question_input_ids = body_input_ids[:body_length]\n",
    "        if title_length > 0:\n",
    "            question_input_ids = (\n",
    "                title_input_ids[:title_length]\n",
    "                + [self.tokenizer.sep_token_id]\n",
    "                + question_input_ids\n",
    "            )\n",
    "        answer_input_ids = answer_input_ids[:answer_length]\n",
    "\n",
    "        input_ids = self.tokenizer.build_inputs_with_special_tokens(\n",
    "            question_input_ids, answer_input_ids if answer_length > 0 else None\n",
    "        )\n",
    "        token_type_ids = self.tokenizer.create_token_type_ids_from_sequences(\n",
    "            question_input_ids, answer_input_ids\n",
    "        )\n",
    "        attention_mask = [1.0] * len(input_ids)\n",
    "\n",
    "        return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "    def _get_text(self, index):\n",
    "        title = self.question_title[index] if self.question_title is not None else None\n",
    "        body = self.question_body[index] if self.question_body is not None else None\n",
    "        answer = self.answer[index] if self.answer is not None else None\n",
    "\n",
    "        def apply_transform(txt, transform):\n",
    "            if transform is not None:\n",
    "                return transform(txt, idx=index)\n",
    "            else:\n",
    "                return txt\n",
    "\n",
    "        title, body, answer = [\n",
    "            apply_transform(txt, transform)\n",
    "            for txt, transform in zip(\n",
    "                [title, body, answer],\n",
    "                [self.title_transform, self.body_transform, self.answer_transform],\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        return title, body, answer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title, body, answer = self._get_text(index)\n",
    "\n",
    "        input_ids, attention_mask, token_type_ids = self._process(title, body, answer)\n",
    "        targets = self.targets[index]\n",
    "\n",
    "        input_ids, attention_mask, token_type_ids = map(\n",
    "            torch.LongTensor, [input_ids, attention_mask, token_type_ids]\n",
    "        )\n",
    "        targets = torch.FloatTensor(targets)\n",
    "\n",
    "        return (input_ids, attention_mask, token_type_ids), targets\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.answer is not None:\n",
    "            return len(self.answer)\n",
    "        elif self.question_title is not None:\n",
    "            return len(self.question_title)\n",
    "        else:\n",
    "            return len(self.question_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestQuestDataset(QuestDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_df,\n",
    "        tokenizer,\n",
    "        max_seg_length=512,\n",
    "        answer_ratio=0.5,\n",
    "        title_ratio=0.5,\n",
    "        # Michael's Notes: Changed it so it only considers the question body\n",
    "        use_title=False,\n",
    "        use_body=True,\n",
    "        use_answer=False,\n",
    "        title_col=\"question_title\",\n",
    "        body_col=\"question_body\",\n",
    "        answer_col=\"answer\",\n",
    "    ):\n",
    "        super(TestQuestDataset, self).__init__(\n",
    "            data_df=data_df,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seg_length=max_seg_length,\n",
    "            target_cols=None,\n",
    "            answer_ratio=answer_ratio,\n",
    "            title_ratio=title_ratio,\n",
    "            use_title=use_title,\n",
    "            use_body=use_body,\n",
    "            use_answer=use_answer,\n",
    "            title_col=title_col,\n",
    "            body_col=body_col,\n",
    "            answer_col=answer_col,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title, body, answer = self._get_text(index)\n",
    "\n",
    "        input_ids, attention_mask, token_type_ids = self._process(title, body, answer)\n",
    "        input_ids, attention_mask, token_type_ids = map(\n",
    "            torch.LongTensor, [input_ids, attention_mask, token_type_ids]\n",
    "        )\n",
    "        return (input_ids, attention_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, columns, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            pred = torch_to_numpy(model(*torch_to(batch, device)))\n",
    "            preds.append(pred)\n",
    "\n",
    "    preds = np.vstack(preds)\n",
    "\n",
    "    preds = torch.sigmoid(torch.from_numpy(preds)).numpy()\n",
    "    preds = np.clip(preds, 0, 1 - 1e-8)\n",
    "    preds = pd.DataFrame(preds, columns=columns)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_numpy(obj, copy=False):\n",
    "    if copy:\n",
    "        func = lambda t: t.cpu().detach().numpy().copy()\n",
    "    else:\n",
    "        func = lambda t: t.cpu().detach().numpy()\n",
    "    return torch_apply(obj, func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to(obj, *args, **kargs):\n",
    "    return torch_apply(obj, lambda t: t.to(*args, **kargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_apply(obj, func):\n",
    "    fn = lambda t: func(t) if torch.is_tensor(t) else t\n",
    "    return _apply(obj, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply(obj, func):\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return type(obj)(_apply(el, func) for el in obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _apply(el, func) for k, el in obj.items()}\n",
    "    return func(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg:\n",
    "    pass\n",
    "    \n",
    "args = Arg()   \n",
    "args.data_path = Path('/home/ubuntu/existing-projects/modified-qa-labeler/custom-input-output/')\n",
    "args.model_dir = Path('/home/ubuntu/existing-projects/modified-qa-labeler/model1_ckpt/')\n",
    "args.sub_file = Path('/home/ubuntu/existing-projects/modified-qa-labeler/output/model1_submission.csv')\n",
    "args.batch_size = 8\n",
    "args.num_workers = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_model(targets=ALL_TARGETS):\n",
    "        config = BertConfig.from_json_file(\n",
    "            args.model_dir / \"stackx-base-cased-config.json\"\n",
    "        )\n",
    "        config.__dict__[\"num_labels\"] = len(targets)\n",
    "\n",
    "        model = BertForQuestRegression(config)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_checkpoints(checkpoints, test_loader, targets, device=\"cuda\"):\n",
    "        model = get_model(targets)\n",
    "        pred = []\n",
    "\n",
    "        for path in checkpoints:\n",
    "            model.load(path, map_location=\"cpu\")\n",
    "            pred.append(predict(model, test_loader, targets, device=device))\n",
    "\n",
    "        pred = np.mean([p[targets].values for p in pred], axis=0)\n",
    "        pred = np.clip(pred, 0, 1 - 1e-8)\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        return pd.DataFrame(pred, columns=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(args.data_path / \"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame(df, tokenizer_path):\n",
    "    tokenizer = BertTokenizer(\n",
    "        args.model_dir / \"stackx-base-cased-vocab.txt\", do_lower_case=False\n",
    "    )\n",
    "    checkpoints = list(args.model_dir.glob(\"*.pth\"))\n",
    "    dataset = TestQuestDataset(df, tokenizer, max_seg_length=512)\n",
    "    dataset_loader = DataLoader(\n",
    "        dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "    return predict_test_checkpoints(checkpoints, dataset_loader, ALL_TARGETS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test[0:1]\n",
    "# test_df = pd.DataFrame(test_df, columns=['question_title', 'question_body', 'answer'])\n",
    "# test_df['question_title'] = 'Foo'\n",
    "# predict_frame(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  8.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.03it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.02it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.91it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "with open('custom-input-output/khan_questions.json') as jsonfile:\n",
    "    contents = json.load(jsonfile)\n",
    "question_arr = np.array(contents)\n",
    "frame = pd.DataFrame(question_arr, columns=['question_body'])\n",
    "frame['question_title'] = ''\n",
    "frame['answer'] = ''\n",
    "tokenizer_path = \n",
    "labels = predict_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why didn't we call the war of 1812 ,world war 1?</td>\n",
       "      <td>0.945643</td>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.179526</td>\n",
       "      <td>0.837070</td>\n",
       "      <td>0.875727</td>\n",
       "      <td>0.783926</td>\n",
       "      <td>0.723753</td>\n",
       "      <td>0.669387</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.081532</td>\n",
       "      <td>0.026037</td>\n",
       "      <td>0.017439</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.940050</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.881338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why the Federalist Party was dissoluted after ...</td>\n",
       "      <td>0.927207</td>\n",
       "      <td>0.862812</td>\n",
       "      <td>0.230581</td>\n",
       "      <td>0.769753</td>\n",
       "      <td>0.816946</td>\n",
       "      <td>0.767172</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.648196</td>\n",
       "      <td>0.035061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028899</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.029043</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.025250</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>0.958029</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.868621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what was discussed at the Hartford convention</td>\n",
       "      <td>0.930462</td>\n",
       "      <td>0.714814</td>\n",
       "      <td>0.173825</td>\n",
       "      <td>0.881098</td>\n",
       "      <td>0.845838</td>\n",
       "      <td>0.797951</td>\n",
       "      <td>0.655597</td>\n",
       "      <td>0.597833</td>\n",
       "      <td>0.032063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065970</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.231092</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.788448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After the War of 1812, did the British stop tr...</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>0.723829</td>\n",
       "      <td>0.067224</td>\n",
       "      <td>0.857686</td>\n",
       "      <td>0.893337</td>\n",
       "      <td>0.898400</td>\n",
       "      <td>0.703929</td>\n",
       "      <td>0.720916</td>\n",
       "      <td>0.218027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860559</td>\n",
       "      <td>0.026775</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.021412</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.343612</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.924115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was the War of 1812 really when US citizens st...</td>\n",
       "      <td>0.961232</td>\n",
       "      <td>0.836647</td>\n",
       "      <td>0.173030</td>\n",
       "      <td>0.719276</td>\n",
       "      <td>0.843397</td>\n",
       "      <td>0.765005</td>\n",
       "      <td>0.710112</td>\n",
       "      <td>0.722150</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711140</td>\n",
       "      <td>0.026368</td>\n",
       "      <td>0.019887</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.917618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Most of the events leading up to America growi...</td>\n",
       "      <td>0.946165</td>\n",
       "      <td>0.739660</td>\n",
       "      <td>0.442933</td>\n",
       "      <td>0.658478</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.298733</td>\n",
       "      <td>0.745040</td>\n",
       "      <td>0.760461</td>\n",
       "      <td>0.049653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043941</td>\n",
       "      <td>0.019796</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.724360</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.882818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Couldn't someone argue that the French and Ind...</td>\n",
       "      <td>0.931253</td>\n",
       "      <td>0.624015</td>\n",
       "      <td>0.150641</td>\n",
       "      <td>0.533234</td>\n",
       "      <td>0.849955</td>\n",
       "      <td>0.586269</td>\n",
       "      <td>0.708665</td>\n",
       "      <td>0.716302</td>\n",
       "      <td>0.368662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184449</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>0.230627</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.019552</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.697787</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.847382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>who won the war of 1812</td>\n",
       "      <td>0.938526</td>\n",
       "      <td>0.815289</td>\n",
       "      <td>0.121631</td>\n",
       "      <td>0.939695</td>\n",
       "      <td>0.862525</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>0.625190</td>\n",
       "      <td>0.550433</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.050493</td>\n",
       "      <td>0.620614</td>\n",
       "      <td>0.043319</td>\n",
       "      <td>0.048633</td>\n",
       "      <td>0.125697</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>0.791754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>why did it all happen?</td>\n",
       "      <td>0.917440</td>\n",
       "      <td>0.826733</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.775816</td>\n",
       "      <td>0.823020</td>\n",
       "      <td>0.738261</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017735</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.025306</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>0.965079</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.870301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>did any other European countries fight in the ...</td>\n",
       "      <td>0.947529</td>\n",
       "      <td>0.713103</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>0.866881</td>\n",
       "      <td>0.909550</td>\n",
       "      <td>0.912919</td>\n",
       "      <td>0.685022</td>\n",
       "      <td>0.627767</td>\n",
       "      <td>0.178557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857553</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>0.019522</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.148611</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.027002</td>\n",
       "      <td>0.302099</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.862474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How did the \"war hawks\" show their dissent?</td>\n",
       "      <td>0.942125</td>\n",
       "      <td>0.842718</td>\n",
       "      <td>0.187458</td>\n",
       "      <td>0.842259</td>\n",
       "      <td>0.833297</td>\n",
       "      <td>0.816936</td>\n",
       "      <td>0.728185</td>\n",
       "      <td>0.649183</td>\n",
       "      <td>0.031751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.885889</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.892672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So I know this is completely off topic but, wh...</td>\n",
       "      <td>0.932699</td>\n",
       "      <td>0.769495</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.831718</td>\n",
       "      <td>0.674182</td>\n",
       "      <td>0.718848</td>\n",
       "      <td>0.679293</td>\n",
       "      <td>0.060122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.913112</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.818974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are some causes of the war of 1812?</td>\n",
       "      <td>0.944052</td>\n",
       "      <td>0.841819</td>\n",
       "      <td>0.156447</td>\n",
       "      <td>0.739604</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.717007</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.636671</td>\n",
       "      <td>0.042957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>0.028763</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.037577</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.031909</td>\n",
       "      <td>0.857991</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>0.878656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Discussion of what sort was held at the Hartfo...</td>\n",
       "      <td>0.947009</td>\n",
       "      <td>0.775848</td>\n",
       "      <td>0.119071</td>\n",
       "      <td>0.911780</td>\n",
       "      <td>0.856297</td>\n",
       "      <td>0.780094</td>\n",
       "      <td>0.638402</td>\n",
       "      <td>0.611054</td>\n",
       "      <td>0.062881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177883</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.092059</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.017283</td>\n",
       "      <td>0.027672</td>\n",
       "      <td>0.107526</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.849116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Were British looking to reclaim their former t...</td>\n",
       "      <td>0.964979</td>\n",
       "      <td>0.847420</td>\n",
       "      <td>0.065044</td>\n",
       "      <td>0.926196</td>\n",
       "      <td>0.880899</td>\n",
       "      <td>0.882908</td>\n",
       "      <td>0.710508</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.120756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836334</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>0.027352</td>\n",
       "      <td>0.096740</td>\n",
       "      <td>0.024484</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.240323</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.923122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How had American Indian's survive/revive their...</td>\n",
       "      <td>0.958785</td>\n",
       "      <td>0.887955</td>\n",
       "      <td>0.156612</td>\n",
       "      <td>0.749842</td>\n",
       "      <td>0.872533</td>\n",
       "      <td>0.737439</td>\n",
       "      <td>0.743941</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.049596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.013582</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>0.043688</td>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.080687</td>\n",
       "      <td>0.778291</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.926990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Why is the war of 1812 sometimes referred to a...</td>\n",
       "      <td>0.954736</td>\n",
       "      <td>0.888066</td>\n",
       "      <td>0.174953</td>\n",
       "      <td>0.824703</td>\n",
       "      <td>0.877501</td>\n",
       "      <td>0.792417</td>\n",
       "      <td>0.735019</td>\n",
       "      <td>0.687516</td>\n",
       "      <td>0.049355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.073763</td>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.016896</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.939724</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.898381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How did the countries justify this war?</td>\n",
       "      <td>0.932631</td>\n",
       "      <td>0.833340</td>\n",
       "      <td>0.204371</td>\n",
       "      <td>0.693488</td>\n",
       "      <td>0.857979</td>\n",
       "      <td>0.702685</td>\n",
       "      <td>0.737328</td>\n",
       "      <td>0.669746</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>0.027301</td>\n",
       "      <td>0.033468</td>\n",
       "      <td>0.098886</td>\n",
       "      <td>0.896671</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.889216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Did relations with Great Britain become better...</td>\n",
       "      <td>0.961726</td>\n",
       "      <td>0.766960</td>\n",
       "      <td>0.249536</td>\n",
       "      <td>0.779526</td>\n",
       "      <td>0.673617</td>\n",
       "      <td>0.708296</td>\n",
       "      <td>0.720093</td>\n",
       "      <td>0.712084</td>\n",
       "      <td>0.213550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804858</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>0.018807</td>\n",
       "      <td>0.014445</td>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.914075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Would the US and British have had worse relati...</td>\n",
       "      <td>0.966069</td>\n",
       "      <td>0.847588</td>\n",
       "      <td>0.130318</td>\n",
       "      <td>0.849447</td>\n",
       "      <td>0.815942</td>\n",
       "      <td>0.845853</td>\n",
       "      <td>0.713094</td>\n",
       "      <td>0.676627</td>\n",
       "      <td>0.109986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848051</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>0.018846</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.365446</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.923498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What does our flag represent? What other merci...</td>\n",
       "      <td>0.951328</td>\n",
       "      <td>0.674914</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>0.748834</td>\n",
       "      <td>0.961197</td>\n",
       "      <td>0.815857</td>\n",
       "      <td>0.654629</td>\n",
       "      <td>0.621895</td>\n",
       "      <td>0.535162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070042</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.384574</td>\n",
       "      <td>0.258732</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.047540</td>\n",
       "      <td>0.470497</td>\n",
       "      <td>0.005890</td>\n",
       "      <td>0.875630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How did the War of 1812 impact America's economy?</td>\n",
       "      <td>0.950235</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>0.129286</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.819394</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.666181</td>\n",
       "      <td>0.043504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.025528</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.030513</td>\n",
       "      <td>0.064245</td>\n",
       "      <td>0.883443</td>\n",
       "      <td>0.004368</td>\n",
       "      <td>0.919544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What was One of the main reasons why United St...</td>\n",
       "      <td>0.955806</td>\n",
       "      <td>0.893892</td>\n",
       "      <td>0.174831</td>\n",
       "      <td>0.729945</td>\n",
       "      <td>0.845263</td>\n",
       "      <td>0.700295</td>\n",
       "      <td>0.722019</td>\n",
       "      <td>0.680152</td>\n",
       "      <td>0.035847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>0.054009</td>\n",
       "      <td>0.016954</td>\n",
       "      <td>0.031633</td>\n",
       "      <td>0.024997</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>0.892489</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.891914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What caused the war of 1812 to start?</td>\n",
       "      <td>0.953307</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.087176</td>\n",
       "      <td>0.851362</td>\n",
       "      <td>0.904669</td>\n",
       "      <td>0.851139</td>\n",
       "      <td>0.723808</td>\n",
       "      <td>0.629056</td>\n",
       "      <td>0.032672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.025016</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.039685</td>\n",
       "      <td>0.038429</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.917058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>If the U.S clearly stated they were neutral du...</td>\n",
       "      <td>0.947676</td>\n",
       "      <td>0.842920</td>\n",
       "      <td>0.232379</td>\n",
       "      <td>0.716390</td>\n",
       "      <td>0.830770</td>\n",
       "      <td>0.753290</td>\n",
       "      <td>0.750319</td>\n",
       "      <td>0.711178</td>\n",
       "      <td>0.083140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026343</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.018241</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0.958397</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.887449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>why did the tribes decide to help the British?</td>\n",
       "      <td>0.934199</td>\n",
       "      <td>0.838447</td>\n",
       "      <td>0.239755</td>\n",
       "      <td>0.784916</td>\n",
       "      <td>0.803104</td>\n",
       "      <td>0.758341</td>\n",
       "      <td>0.717080</td>\n",
       "      <td>0.659151</td>\n",
       "      <td>0.037060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.023112</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.872515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Why would the British want to create an Indian...</td>\n",
       "      <td>0.943606</td>\n",
       "      <td>0.866169</td>\n",
       "      <td>0.182579</td>\n",
       "      <td>0.788157</td>\n",
       "      <td>0.849986</td>\n",
       "      <td>0.798728</td>\n",
       "      <td>0.720081</td>\n",
       "      <td>0.672242</td>\n",
       "      <td>0.043496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>0.028290</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.960245</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.893113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Why is Andrew Jackson celebrated in the twenty...</td>\n",
       "      <td>0.948769</td>\n",
       "      <td>0.888088</td>\n",
       "      <td>0.388229</td>\n",
       "      <td>0.757147</td>\n",
       "      <td>0.700666</td>\n",
       "      <td>0.605702</td>\n",
       "      <td>0.750383</td>\n",
       "      <td>0.714879</td>\n",
       "      <td>0.050220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029414</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.019072</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>0.943799</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.908518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How long did the war last and why?</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.873667</td>\n",
       "      <td>0.120356</td>\n",
       "      <td>0.638048</td>\n",
       "      <td>0.919544</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.730412</td>\n",
       "      <td>0.653837</td>\n",
       "      <td>0.213040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>0.044041</td>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.087599</td>\n",
       "      <td>0.060955</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>0.909056</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.922161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What was discussed at the Hartford convention?</td>\n",
       "      <td>0.966863</td>\n",
       "      <td>0.889606</td>\n",
       "      <td>0.150681</td>\n",
       "      <td>0.880391</td>\n",
       "      <td>0.899195</td>\n",
       "      <td>0.783639</td>\n",
       "      <td>0.692188</td>\n",
       "      <td>0.637042</td>\n",
       "      <td>0.053889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.016264</td>\n",
       "      <td>0.152985</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.016152</td>\n",
       "      <td>0.037298</td>\n",
       "      <td>0.222701</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.906115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Can you explain the Treaty of Ghent a little m...</td>\n",
       "      <td>0.933331</td>\n",
       "      <td>0.727263</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>0.864646</td>\n",
       "      <td>0.795318</td>\n",
       "      <td>0.616276</td>\n",
       "      <td>0.683931</td>\n",
       "      <td>0.687586</td>\n",
       "      <td>0.040776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278265</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.062997</td>\n",
       "      <td>0.063944</td>\n",
       "      <td>0.052327</td>\n",
       "      <td>0.063981</td>\n",
       "      <td>0.292718</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.854173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Did the Americans always have to resort to bat...</td>\n",
       "      <td>0.970040</td>\n",
       "      <td>0.712025</td>\n",
       "      <td>0.138184</td>\n",
       "      <td>0.708086</td>\n",
       "      <td>0.860752</td>\n",
       "      <td>0.763373</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.756894</td>\n",
       "      <td>0.607151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.031708</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.051837</td>\n",
       "      <td>0.484257</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.931855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What effect did it have on Americans?</td>\n",
       "      <td>0.970200</td>\n",
       "      <td>0.919579</td>\n",
       "      <td>0.215056</td>\n",
       "      <td>0.778168</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.758504</td>\n",
       "      <td>0.761252</td>\n",
       "      <td>0.716253</td>\n",
       "      <td>0.052997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041982</td>\n",
       "      <td>0.044517</td>\n",
       "      <td>0.037633</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.021171</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.764505</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.941058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>At what moment did US-British relations reach ...</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.937413</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.817215</td>\n",
       "      <td>0.926895</td>\n",
       "      <td>0.863490</td>\n",
       "      <td>0.729580</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059895</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.028740</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>0.035206</td>\n",
       "      <td>0.536344</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.942596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Why would Britain try to make the US side with...</td>\n",
       "      <td>0.945780</td>\n",
       "      <td>0.865781</td>\n",
       "      <td>0.298812</td>\n",
       "      <td>0.747301</td>\n",
       "      <td>0.748671</td>\n",
       "      <td>0.707474</td>\n",
       "      <td>0.743430</td>\n",
       "      <td>0.707179</td>\n",
       "      <td>0.050945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029628</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.023445</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>0.958820</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.892647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What are causes of the war of 1812?</td>\n",
       "      <td>0.942764</td>\n",
       "      <td>0.850770</td>\n",
       "      <td>0.110663</td>\n",
       "      <td>0.775197</td>\n",
       "      <td>0.877223</td>\n",
       "      <td>0.783016</td>\n",
       "      <td>0.707931</td>\n",
       "      <td>0.619267</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.024463</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.050608</td>\n",
       "      <td>0.071144</td>\n",
       "      <td>0.033441</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.819942</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.877305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What were the results of the War of 1812?</td>\n",
       "      <td>0.963898</td>\n",
       "      <td>0.884548</td>\n",
       "      <td>0.068456</td>\n",
       "      <td>0.872833</td>\n",
       "      <td>0.934795</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>0.676501</td>\n",
       "      <td>0.617247</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>0.067456</td>\n",
       "      <td>0.297629</td>\n",
       "      <td>0.034252</td>\n",
       "      <td>0.061467</td>\n",
       "      <td>0.272453</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.910496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>How did Jackson beat the British in the battle...</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.895918</td>\n",
       "      <td>0.106773</td>\n",
       "      <td>0.842615</td>\n",
       "      <td>0.896516</td>\n",
       "      <td>0.828232</td>\n",
       "      <td>0.725558</td>\n",
       "      <td>0.627355</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016392</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.671842</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.915569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The War of 1812, which lasted from June 18, 18...</td>\n",
       "      <td>0.930721</td>\n",
       "      <td>0.777733</td>\n",
       "      <td>0.331127</td>\n",
       "      <td>0.623960</td>\n",
       "      <td>0.688464</td>\n",
       "      <td>0.652803</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.677965</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.017587</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.955796</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.858478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Why did Napoleon end up abdicating his throne?</td>\n",
       "      <td>0.941589</td>\n",
       "      <td>0.878625</td>\n",
       "      <td>0.274569</td>\n",
       "      <td>0.822013</td>\n",
       "      <td>0.763072</td>\n",
       "      <td>0.716483</td>\n",
       "      <td>0.747398</td>\n",
       "      <td>0.678984</td>\n",
       "      <td>0.035912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>0.953327</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.897983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Why did Andrew Jackson attempt to destroy the ...</td>\n",
       "      <td>0.948045</td>\n",
       "      <td>0.867085</td>\n",
       "      <td>0.429452</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.625233</td>\n",
       "      <td>0.569503</td>\n",
       "      <td>0.760161</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027924</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>0.945313</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.899254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How did the war of 1812 end? What started The ...</td>\n",
       "      <td>0.945439</td>\n",
       "      <td>0.789637</td>\n",
       "      <td>0.053602</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>0.842170</td>\n",
       "      <td>0.720677</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.444780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022802</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.037843</td>\n",
       "      <td>0.115853</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.158487</td>\n",
       "      <td>0.909255</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.906278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What were causes and effects of War of 1812?</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>0.725445</td>\n",
       "      <td>0.927050</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.699228</td>\n",
       "      <td>0.621735</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.071541</td>\n",
       "      <td>0.054231</td>\n",
       "      <td>0.079653</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>0.032736</td>\n",
       "      <td>0.038079</td>\n",
       "      <td>0.636195</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.892575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>How did the US military know to focus on seizi...</td>\n",
       "      <td>0.935447</td>\n",
       "      <td>0.810894</td>\n",
       "      <td>0.159636</td>\n",
       "      <td>0.746615</td>\n",
       "      <td>0.833665</td>\n",
       "      <td>0.785249</td>\n",
       "      <td>0.738147</td>\n",
       "      <td>0.675053</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>0.017349</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.032074</td>\n",
       "      <td>0.066478</td>\n",
       "      <td>0.902813</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.886924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What was the very main reason why the war of 1...</td>\n",
       "      <td>0.937810</td>\n",
       "      <td>0.694553</td>\n",
       "      <td>0.094512</td>\n",
       "      <td>0.604241</td>\n",
       "      <td>0.898935</td>\n",
       "      <td>0.819697</td>\n",
       "      <td>0.700818</td>\n",
       "      <td>0.649690</td>\n",
       "      <td>0.323418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193316</td>\n",
       "      <td>0.021928</td>\n",
       "      <td>0.021695</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.026004</td>\n",
       "      <td>0.941721</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.849627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>How many Native Americans were murdered by the...</td>\n",
       "      <td>0.972549</td>\n",
       "      <td>0.914869</td>\n",
       "      <td>0.071195</td>\n",
       "      <td>0.918761</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.844030</td>\n",
       "      <td>0.686670</td>\n",
       "      <td>0.658879</td>\n",
       "      <td>0.040775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044207</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.431445</td>\n",
       "      <td>0.034477</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.920937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Did any colonists dislike the actions taken ag...</td>\n",
       "      <td>0.965150</td>\n",
       "      <td>0.787131</td>\n",
       "      <td>0.278728</td>\n",
       "      <td>0.639492</td>\n",
       "      <td>0.755444</td>\n",
       "      <td>0.644614</td>\n",
       "      <td>0.724225</td>\n",
       "      <td>0.720410</td>\n",
       "      <td>0.441997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740672</td>\n",
       "      <td>0.030753</td>\n",
       "      <td>0.039402</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>0.013152</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.555431</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.932611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>It was to solve a border skirmish between Cana...</td>\n",
       "      <td>0.929184</td>\n",
       "      <td>0.671884</td>\n",
       "      <td>0.233286</td>\n",
       "      <td>0.790176</td>\n",
       "      <td>0.605107</td>\n",
       "      <td>0.669802</td>\n",
       "      <td>0.658477</td>\n",
       "      <td>0.654093</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060798</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.021723</td>\n",
       "      <td>0.055578</td>\n",
       "      <td>0.060528</td>\n",
       "      <td>0.698285</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.817376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question_body  \\\n",
       "0    why didn't we call the war of 1812 ,world war 1?   \n",
       "1   Why the Federalist Party was dissoluted after ...   \n",
       "2       what was discussed at the Hartford convention   \n",
       "3   After the War of 1812, did the British stop tr...   \n",
       "4   Was the War of 1812 really when US citizens st...   \n",
       "5   Most of the events leading up to America growi...   \n",
       "6   Couldn't someone argue that the French and Ind...   \n",
       "7                             who won the war of 1812   \n",
       "8                              why did it all happen?   \n",
       "9   did any other European countries fight in the ...   \n",
       "10        How did the \"war hawks\" show their dissent?   \n",
       "11  So I know this is completely off topic but, wh...   \n",
       "12           What are some causes of the war of 1812?   \n",
       "13  Discussion of what sort was held at the Hartfo...   \n",
       "14  Were British looking to reclaim their former t...   \n",
       "15  How had American Indian's survive/revive their...   \n",
       "16  Why is the war of 1812 sometimes referred to a...   \n",
       "17            How did the countries justify this war?   \n",
       "18  Did relations with Great Britain become better...   \n",
       "19  Would the US and British have had worse relati...   \n",
       "20  What does our flag represent? What other merci...   \n",
       "21  How did the War of 1812 impact America's economy?   \n",
       "22  What was One of the main reasons why United St...   \n",
       "23              What caused the war of 1812 to start?   \n",
       "24  If the U.S clearly stated they were neutral du...   \n",
       "25     why did the tribes decide to help the British?   \n",
       "26  Why would the British want to create an Indian...   \n",
       "27  Why is Andrew Jackson celebrated in the twenty...   \n",
       "28                 How long did the war last and why?   \n",
       "29     What was discussed at the Hartford convention?   \n",
       "30  Can you explain the Treaty of Ghent a little m...   \n",
       "31  Did the Americans always have to resort to bat...   \n",
       "32              What effect did it have on Americans?   \n",
       "33  At what moment did US-British relations reach ...   \n",
       "34  Why would Britain try to make the US side with...   \n",
       "35                What are causes of the war of 1812?   \n",
       "36          What were the results of the War of 1812?   \n",
       "37  How did Jackson beat the British in the battle...   \n",
       "38  The War of 1812, which lasted from June 18, 18...   \n",
       "39     Why did Napoleon end up abdicating his throne?   \n",
       "40  Why did Andrew Jackson attempt to destroy the ...   \n",
       "41  How did the war of 1812 end? What started The ...   \n",
       "42       What were causes and effects of War of 1812?   \n",
       "43  How did the US military know to focus on seizi...   \n",
       "44  What was the very main reason why the war of 1...   \n",
       "45  How many Native Americans were murdered by the...   \n",
       "46  Did any colonists dislike the actions taken ag...   \n",
       "47  It was to solve a border skirmish between Cana...   \n",
       "\n",
       "    question_asker_intent_understanding  question_body_critical  \\\n",
       "0                              0.945643                0.868897   \n",
       "1                              0.927207                0.862812   \n",
       "2                              0.930462                0.714814   \n",
       "3                              0.968957                0.723829   \n",
       "4                              0.961232                0.836647   \n",
       "5                              0.946165                0.739660   \n",
       "6                              0.931253                0.624015   \n",
       "7                              0.938526                0.815289   \n",
       "8                              0.917440                0.826733   \n",
       "9                              0.947529                0.713103   \n",
       "10                             0.942125                0.842718   \n",
       "11                             0.932699                0.769495   \n",
       "12                             0.944052                0.841819   \n",
       "13                             0.947009                0.775848   \n",
       "14                             0.964979                0.847420   \n",
       "15                             0.958785                0.887955   \n",
       "16                             0.954736                0.888066   \n",
       "17                             0.932631                0.833340   \n",
       "18                             0.961726                0.766960   \n",
       "19                             0.966069                0.847588   \n",
       "20                             0.951328                0.674914   \n",
       "21                             0.950235                0.909926   \n",
       "22                             0.955806                0.893892   \n",
       "23                             0.953307                0.889641   \n",
       "24                             0.947676                0.842920   \n",
       "25                             0.934199                0.838447   \n",
       "26                             0.943606                0.866169   \n",
       "27                             0.948769                0.888088   \n",
       "28                             0.949750                0.873667   \n",
       "29                             0.966863                0.889606   \n",
       "30                             0.933331                0.727263   \n",
       "31                             0.970040                0.712025   \n",
       "32                             0.970200                0.919579   \n",
       "33                             0.971908                0.937413   \n",
       "34                             0.945780                0.865781   \n",
       "35                             0.942764                0.850770   \n",
       "36                             0.963898                0.884548   \n",
       "37                             0.953497                0.895918   \n",
       "38                             0.930721                0.777733   \n",
       "39                             0.941589                0.878625   \n",
       "40                             0.948045                0.867085   \n",
       "41                             0.945439                0.789637   \n",
       "42                             0.956402                0.883212   \n",
       "43                             0.935447                0.810894   \n",
       "44                             0.937810                0.694553   \n",
       "45                             0.972549                0.914869   \n",
       "46                             0.965150                0.787131   \n",
       "47                             0.929184                0.671884   \n",
       "\n",
       "    question_conversational  question_expect_short_answer  \\\n",
       "0                  0.179526                      0.837070   \n",
       "1                  0.230581                      0.769753   \n",
       "2                  0.173825                      0.881098   \n",
       "3                  0.067224                      0.857686   \n",
       "4                  0.173030                      0.719276   \n",
       "5                  0.442933                      0.658478   \n",
       "6                  0.150641                      0.533234   \n",
       "7                  0.121631                      0.939695   \n",
       "8                  0.237000                      0.775816   \n",
       "9                  0.053253                      0.866881   \n",
       "10                 0.187458                      0.842259   \n",
       "11                 0.204102                      0.763948   \n",
       "12                 0.156447                      0.739604   \n",
       "13                 0.119071                      0.911780   \n",
       "14                 0.065044                      0.926196   \n",
       "15                 0.156612                      0.749842   \n",
       "16                 0.174953                      0.824703   \n",
       "17                 0.204371                      0.693488   \n",
       "18                 0.249536                      0.779526   \n",
       "19                 0.130318                      0.849447   \n",
       "20                 0.045759                      0.748834   \n",
       "21                 0.129286                      0.719700   \n",
       "22                 0.174831                      0.729945   \n",
       "23                 0.087176                      0.851362   \n",
       "24                 0.232379                      0.716390   \n",
       "25                 0.239755                      0.784916   \n",
       "26                 0.182579                      0.788157   \n",
       "27                 0.388229                      0.757147   \n",
       "28                 0.120356                      0.638048   \n",
       "29                 0.150681                      0.880391   \n",
       "30                 0.098744                      0.864646   \n",
       "31                 0.138184                      0.708086   \n",
       "32                 0.215056                      0.778168   \n",
       "33                 0.075145                      0.817215   \n",
       "34                 0.298812                      0.747301   \n",
       "35                 0.110663                      0.775197   \n",
       "36                 0.068456                      0.872833   \n",
       "37                 0.106773                      0.842615   \n",
       "38                 0.331127                      0.623960   \n",
       "39                 0.274569                      0.822013   \n",
       "40                 0.429452                      0.749132   \n",
       "41                 0.053602                      0.523795   \n",
       "42                 0.075048                      0.725445   \n",
       "43                 0.159636                      0.746615   \n",
       "44                 0.094512                      0.604241   \n",
       "45                 0.071195                      0.918761   \n",
       "46                 0.278728                      0.639492   \n",
       "47                 0.233286                      0.790176   \n",
       "\n",
       "    question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.875727                               0.783926   \n",
       "1                0.816946                               0.767172   \n",
       "2                0.845838                               0.797951   \n",
       "3                0.893337                               0.898400   \n",
       "4                0.843397                               0.765005   \n",
       "5                0.399217                               0.298733   \n",
       "6                0.849955                               0.586269   \n",
       "7                0.862525                               0.790204   \n",
       "8                0.823020                               0.738261   \n",
       "9                0.909550                               0.912919   \n",
       "10               0.833297                               0.816936   \n",
       "11               0.831718                               0.674182   \n",
       "12               0.827100                               0.717007   \n",
       "13               0.856297                               0.780094   \n",
       "14               0.880899                               0.882908   \n",
       "15               0.872533                               0.737439   \n",
       "16               0.877501                               0.792417   \n",
       "17               0.857979                               0.702685   \n",
       "18               0.673617                               0.708296   \n",
       "19               0.815942                               0.845853   \n",
       "20               0.961197                               0.815857   \n",
       "21               0.902098                               0.819394   \n",
       "22               0.845263                               0.700295   \n",
       "23               0.904669                               0.851139   \n",
       "24               0.830770                               0.753290   \n",
       "25               0.803104                               0.758341   \n",
       "26               0.849986                               0.798728   \n",
       "27               0.700666                               0.605702   \n",
       "28               0.919544                               0.743572   \n",
       "29               0.899195                               0.783639   \n",
       "30               0.795318                               0.616276   \n",
       "31               0.860752                               0.763373   \n",
       "32               0.861380                               0.758504   \n",
       "33               0.926895                               0.863490   \n",
       "34               0.748671                               0.707474   \n",
       "35               0.877223                               0.783016   \n",
       "36               0.934795                               0.823007   \n",
       "37               0.896516                               0.828232   \n",
       "38               0.688464                               0.652803   \n",
       "39               0.763072                               0.716483   \n",
       "40               0.625233                               0.569503   \n",
       "41               0.959732                               0.842170   \n",
       "42               0.927050                               0.801429   \n",
       "43               0.833665                               0.785249   \n",
       "44               0.898935                               0.819697   \n",
       "45               0.913386                               0.844030   \n",
       "46               0.755444                               0.644614   \n",
       "47               0.605107                               0.669802   \n",
       "\n",
       "    question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.723753                       0.669387   \n",
       "1                          0.717266                       0.648196   \n",
       "2                          0.655597                       0.597833   \n",
       "3                          0.703929                       0.720916   \n",
       "4                          0.710112                       0.722150   \n",
       "5                          0.745040                       0.760461   \n",
       "6                          0.708665                       0.716302   \n",
       "7                          0.625190                       0.550433   \n",
       "8                          0.715536                       0.611570   \n",
       "9                          0.685022                       0.627767   \n",
       "10                         0.728185                       0.649183   \n",
       "11                         0.718848                       0.679293   \n",
       "12                         0.716087                       0.636671   \n",
       "13                         0.638402                       0.611054   \n",
       "14                         0.710508                       0.716298   \n",
       "15                         0.743941                       0.710293   \n",
       "16                         0.735019                       0.687516   \n",
       "17                         0.737328                       0.669746   \n",
       "18                         0.720093                       0.712084   \n",
       "19                         0.713094                       0.676627   \n",
       "20                         0.654629                       0.621895   \n",
       "21                         0.733645                       0.666181   \n",
       "22                         0.722019                       0.680152   \n",
       "23                         0.723808                       0.629056   \n",
       "24                         0.750319                       0.711178   \n",
       "25                         0.717080                       0.659151   \n",
       "26                         0.720081                       0.672242   \n",
       "27                         0.750383                       0.714879   \n",
       "28                         0.730412                       0.653837   \n",
       "29                         0.692188                       0.637042   \n",
       "30                         0.683931                       0.687586   \n",
       "31                         0.738400                       0.756894   \n",
       "32                         0.761252                       0.716253   \n",
       "33                         0.729580                       0.673121   \n",
       "34                         0.743430                       0.707179   \n",
       "35                         0.707931                       0.619267   \n",
       "36                         0.676501                       0.617247   \n",
       "37                         0.725558                       0.627355   \n",
       "38                         0.714460                       0.677965   \n",
       "39                         0.747398                       0.678984   \n",
       "40                         0.760161                       0.724100   \n",
       "41                         0.720677                       0.659961   \n",
       "42                         0.699228                       0.621735   \n",
       "43                         0.738147                       0.675053   \n",
       "44                         0.700818                       0.649690   \n",
       "45                         0.686670                       0.658879   \n",
       "46                         0.724225                       0.720410   \n",
       "47                         0.658477                       0.654093   \n",
       "\n",
       "    question_multi_intent  ...  question_type_choice  question_type_compare  \\\n",
       "0                0.039323  ...              0.026430               0.023828   \n",
       "1                0.035061  ...              0.028899               0.020764   \n",
       "2                0.032063  ...              0.065970               0.032571   \n",
       "3                0.218027  ...              0.860559               0.026775   \n",
       "4                0.150674  ...              0.711140               0.026368   \n",
       "5                0.049653  ...              0.043941               0.019796   \n",
       "6                0.368662  ...              0.184449               0.023608   \n",
       "7                0.023453  ...              0.063888               0.029847   \n",
       "8                0.045972  ...              0.017735               0.023214   \n",
       "9                0.178557  ...              0.857553               0.015797   \n",
       "10               0.031751  ...              0.017718               0.010707   \n",
       "11               0.060122  ...              0.026957               0.023135   \n",
       "12               0.042957  ...              0.016311               0.028763   \n",
       "13               0.062881  ...              0.177883               0.022251   \n",
       "14               0.120756  ...              0.836334               0.013377   \n",
       "15               0.049596  ...              0.020573               0.009320   \n",
       "16               0.049355  ...              0.035426               0.023144   \n",
       "17               0.043080  ...              0.013470               0.017273   \n",
       "18               0.213550  ...              0.804858               0.034176   \n",
       "19               0.109986  ...              0.848051               0.092741   \n",
       "20               0.535162  ...              0.070042               0.021421   \n",
       "21               0.043504  ...              0.016201               0.019133   \n",
       "22               0.035847  ...              0.020462               0.054009   \n",
       "23               0.032672  ...              0.019808               0.017945   \n",
       "24               0.083140  ...              0.026343               0.019062   \n",
       "25               0.037060  ...              0.019047               0.020383   \n",
       "26               0.043496  ...              0.028666               0.019469   \n",
       "27               0.050220  ...              0.029414               0.023121   \n",
       "28               0.213040  ...              0.019987               0.044041   \n",
       "29               0.053889  ...              0.043693               0.029663   \n",
       "30               0.040776  ...              0.278265               0.011104   \n",
       "31               0.607151  ...              0.794488               0.019213   \n",
       "32               0.052997  ...              0.041982               0.044517   \n",
       "33               0.050794  ...              0.059895               0.026998   \n",
       "34               0.050945  ...              0.029628               0.022758   \n",
       "35               0.044558  ...              0.016394               0.024463   \n",
       "36               0.045153  ...              0.027312               0.026179   \n",
       "37               0.029337  ...              0.016392               0.013829   \n",
       "38               0.075470  ...              0.030464               0.024069   \n",
       "39               0.035912  ...              0.023583               0.017830   \n",
       "40               0.054601  ...              0.027924               0.022266   \n",
       "41               0.444780  ...              0.022802               0.019457   \n",
       "42               0.060263  ...              0.016664               0.071541   \n",
       "43               0.049659  ...              0.029371               0.006289   \n",
       "44               0.323418  ...              0.193316               0.021928   \n",
       "45               0.040775  ...              0.044207               0.014179   \n",
       "46               0.441997  ...              0.740672               0.030753   \n",
       "47               0.021828  ...              0.060798               0.007981   \n",
       "\n",
       "    question_type_consequence  question_type_definition  question_type_entity  \\\n",
       "0                    0.011115                  0.081532              0.026037   \n",
       "1                    0.018978                  0.029043              0.018781   \n",
       "2                    0.015016                  0.159960              0.154743   \n",
       "3                    0.020826                  0.031357              0.021412   \n",
       "4                    0.019887                  0.042975              0.013739   \n",
       "5                    0.019624                  0.015395              0.032630   \n",
       "6                    0.022959                  0.230627              0.033706   \n",
       "7                    0.018001                  0.050493              0.620614   \n",
       "8                    0.025306                  0.037049              0.022860   \n",
       "9                    0.019522                  0.017419              0.148611   \n",
       "10                   0.011861                  0.058596              0.017246   \n",
       "11                   0.012634                  0.095124              0.027175   \n",
       "12                   0.038388                  0.037577              0.053603   \n",
       "13                   0.013487                  0.092059              0.470838   \n",
       "14                   0.016458                  0.027352              0.096740   \n",
       "15                   0.013582                  0.018535              0.043688   \n",
       "16                   0.015070                  0.073763              0.022462   \n",
       "17                   0.019826                  0.060501              0.027301   \n",
       "18                   0.034159                  0.014476              0.018807   \n",
       "19                   0.037902                  0.018846              0.020929   \n",
       "20                   0.019180                  0.384574              0.258732   \n",
       "21                   0.025528                  0.038940              0.015450   \n",
       "22                   0.016954                  0.031633              0.024997   \n",
       "23                   0.025016                  0.031073              0.043647   \n",
       "24                   0.018241                  0.029575              0.018211   \n",
       "25                   0.016805                  0.019982              0.023112   \n",
       "26                   0.016342                  0.017559              0.020791   \n",
       "27                   0.019072                  0.026847              0.027288   \n",
       "28                   0.038138                  0.087599              0.060955   \n",
       "29                   0.016264                  0.152985              0.185607   \n",
       "30                   0.005845                  0.062997              0.063944   \n",
       "31                   0.042229                  0.031708              0.047494   \n",
       "32                   0.037633                  0.047688              0.021862   \n",
       "33                   0.019656                  0.028740              0.096914   \n",
       "34                   0.021782                  0.015862              0.018272   \n",
       "35                   0.039939                  0.050608              0.071144   \n",
       "36                   0.020822                  0.067456              0.297629   \n",
       "37                   0.013671                  0.023332              0.044176   \n",
       "38                   0.016793                  0.019244              0.017192   \n",
       "39                   0.019400                  0.022839              0.023188   \n",
       "40                   0.020723                  0.021366              0.022262   \n",
       "41                   0.037843                  0.115853              0.039267   \n",
       "42                   0.054231                  0.079653              0.085178   \n",
       "43                   0.013251                  0.017349              0.019333   \n",
       "44                   0.021695                  0.046700              0.020306   \n",
       "45                   0.016622                  0.017967              0.431445   \n",
       "46                   0.039402                  0.021853              0.040125   \n",
       "47                   0.011936                  0.010204              0.021723   \n",
       "\n",
       "    question_type_instructions  question_type_procedure  \\\n",
       "0                     0.017439                 0.013348   \n",
       "1                     0.025250                 0.019494   \n",
       "2                     0.018464                 0.052286   \n",
       "3                     0.020929                 0.034210   \n",
       "4                     0.010068                 0.014282   \n",
       "5                     0.026723                 0.037554   \n",
       "6                     0.019552                 0.034865   \n",
       "7                     0.043319                 0.048633   \n",
       "8                     0.038195                 0.027199   \n",
       "9                     0.021195                 0.027002   \n",
       "10                    0.026817                 0.060800   \n",
       "11                    0.016508                 0.014561   \n",
       "12                    0.035721                 0.031909   \n",
       "13                    0.017283                 0.027672   \n",
       "14                    0.024484                 0.026131   \n",
       "15                    0.026922                 0.080687   \n",
       "16                    0.016896                 0.012986   \n",
       "17                    0.033468                 0.098886   \n",
       "18                    0.014445                 0.024460   \n",
       "19                    0.014891                 0.019604   \n",
       "20                    0.028285                 0.047540   \n",
       "21                    0.030513                 0.064245   \n",
       "22                    0.024962                 0.018965   \n",
       "23                    0.039685                 0.038429   \n",
       "24                    0.022799                 0.022092   \n",
       "25                    0.027188                 0.023756   \n",
       "26                    0.028290                 0.018285   \n",
       "27                    0.019309                 0.015368   \n",
       "28                    0.038194                 0.054420   \n",
       "29                    0.016152                 0.037298   \n",
       "30                    0.052327                 0.063981   \n",
       "31                    0.021180                 0.051837   \n",
       "32                    0.021171                 0.023207   \n",
       "33                    0.019636                 0.035206   \n",
       "34                    0.023445                 0.018025   \n",
       "35                    0.033441                 0.037810   \n",
       "36                    0.034252                 0.061467   \n",
       "37                    0.044501                 0.102714   \n",
       "38                    0.017587                 0.016530   \n",
       "39                    0.028397                 0.020654   \n",
       "40                    0.020770                 0.016452   \n",
       "41                    0.053811                 0.158487   \n",
       "42                    0.032736                 0.038079   \n",
       "43                    0.032074                 0.066478   \n",
       "44                    0.028237                 0.026004   \n",
       "45                    0.034477                 0.042166   \n",
       "46                    0.013152                 0.024792   \n",
       "47                    0.055578                 0.060528   \n",
       "\n",
       "    question_type_reason_explanation  question_type_spelling  \\\n",
       "0                           0.940050                0.004743   \n",
       "1                           0.958029                0.005142   \n",
       "2                           0.231092                0.008725   \n",
       "3                           0.343612                0.002573   \n",
       "4                           0.646467                0.002899   \n",
       "5                           0.724360                0.002363   \n",
       "6                           0.697787                0.003578   \n",
       "7                           0.125697                0.008345   \n",
       "8                           0.965079                0.007387   \n",
       "9                           0.302099                0.004380   \n",
       "10                          0.885889                0.003883   \n",
       "11                          0.913112                0.004934   \n",
       "12                          0.857991                0.006224   \n",
       "13                          0.107526                0.007540   \n",
       "14                          0.240323                0.003793   \n",
       "15                          0.778291                0.002491   \n",
       "16                          0.939724                0.005673   \n",
       "17                          0.896671                0.004215   \n",
       "18                          0.501815                0.002815   \n",
       "19                          0.365446                0.004308   \n",
       "20                          0.470497                0.005890   \n",
       "21                          0.883443                0.004368   \n",
       "22                          0.892489                0.004049   \n",
       "23                          0.816521                0.005378   \n",
       "24                          0.958397                0.003691   \n",
       "25                          0.962164                0.004253   \n",
       "26                          0.960245                0.003457   \n",
       "27                          0.943799                0.005065   \n",
       "28                          0.909056                0.007154   \n",
       "29                          0.222701                0.006205   \n",
       "30                          0.292718                0.002530   \n",
       "31                          0.484257                0.003128   \n",
       "32                          0.764505                0.005191   \n",
       "33                          0.536344                0.004683   \n",
       "34                          0.958820                0.003632   \n",
       "35                          0.819942                0.007021   \n",
       "36                          0.272453                0.005957   \n",
       "37                          0.671842                0.003314   \n",
       "38                          0.955796                0.003154   \n",
       "39                          0.953327                0.005176   \n",
       "40                          0.945313                0.004293   \n",
       "41                          0.909255                0.006198   \n",
       "42                          0.636195                0.008928   \n",
       "43                          0.902813                0.002122   \n",
       "44                          0.941721                0.002828   \n",
       "45                          0.210777                0.004187   \n",
       "46                          0.555431                0.002702   \n",
       "47                          0.698285                0.001531   \n",
       "\n",
       "    question_well_written  \n",
       "0                0.881338  \n",
       "1                0.868621  \n",
       "2                0.788448  \n",
       "3                0.924115  \n",
       "4                0.917618  \n",
       "5                0.882818  \n",
       "6                0.847382  \n",
       "7                0.791754  \n",
       "8                0.870301  \n",
       "9                0.862474  \n",
       "10               0.892672  \n",
       "11               0.818974  \n",
       "12               0.878656  \n",
       "13               0.849116  \n",
       "14               0.923122  \n",
       "15               0.926990  \n",
       "16               0.898381  \n",
       "17               0.889216  \n",
       "18               0.914075  \n",
       "19               0.923498  \n",
       "20               0.875630  \n",
       "21               0.919544  \n",
       "22               0.891914  \n",
       "23               0.917058  \n",
       "24               0.887449  \n",
       "25               0.872515  \n",
       "26               0.893113  \n",
       "27               0.908518  \n",
       "28               0.922161  \n",
       "29               0.906115  \n",
       "30               0.854173  \n",
       "31               0.931855  \n",
       "32               0.941058  \n",
       "33               0.942596  \n",
       "34               0.892647  \n",
       "35               0.877305  \n",
       "36               0.910496  \n",
       "37               0.915569  \n",
       "38               0.858478  \n",
       "39               0.897983  \n",
       "40               0.899254  \n",
       "41               0.906278  \n",
       "42               0.892575  \n",
       "43               0.886924  \n",
       "44               0.849627  \n",
       "45               0.920937  \n",
       "46               0.932611  \n",
       "47               0.817376  \n",
       "\n",
       "[48 rows x 22 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame(labels, columns=QUESTION_TARGETS)\n",
    "frames = [frame['question_body'], labels]\n",
    "pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(args.sub_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b90f910b2888eadd647cde567cc3038ed7164c616248994f340a42c9c2af1775"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}